{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------load data module begin-----------------------------------------------------\n",
    "def load_path(data_set, root_dir = 'B:/MURA/MURA-v1.1/', data_type = 'XR_ELBOW'):\n",
    "    # load MURA data and return data path list and label numpy array\n",
    "    data_path = root_dir + data_set + '/' + data_type + '/'\n",
    "    Path = []\n",
    "    labels = []\n",
    "    for root, dirs, files in os.walk(data_path):  # read all images, os.walk returns iterators genertor traverses all files\n",
    "        for name in files:\n",
    "            if root.split('_')[-1] == 'positive':  # positive label == 1；\n",
    "                path_1 = os.path.join(root, name)\n",
    "                Path.append(path_1)\n",
    "                labels += [1]\n",
    "            elif root.split('_')[-1] == 'negative':  # negative label == 1；\n",
    "                path_1 = os.path.join(root, name)\n",
    "                Path.append(path_1)\n",
    "                labels += [0]\n",
    "            else:\n",
    "                continue\n",
    "    labels = np.asarray(labels)\n",
    "    return Path, labels\n",
    "\n",
    "#  path list in, image list out\n",
    "def load_image(Path='../valid', imsize=224):\n",
    "    Images = []\n",
    "    i = 1\n",
    "    for path in Path:\n",
    "\n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None:\n",
    "            print(\"null\")\n",
    "            continue\n",
    "        else:\n",
    "            if i % 500 == 0:\n",
    "                print (\"loading image \", i)\n",
    "            \n",
    "            image = cv2.resize(image, (imsize, imsize))   # resize images\n",
    "            image = randome_rotation_flip(image, imsize)  # predeal images\n",
    "            Images.append(image)\n",
    "            i = i+1\n",
    "\n",
    "    Images = np.asarray(Images).astype('float32')\n",
    "\n",
    "    # normalization\n",
    "    print(\"Starting normalization.......\")\n",
    "    mean = np.mean(Images[:, :, :])\n",
    "    std = np.std(Images[:, :, :])\n",
    "    Images[:, :, :] = (Images[:, :, :] - mean) / std\n",
    "    print(\"normalization finished\")\n",
    "\n",
    "    Images = np.expand_dims(Images, axis=1)\n",
    "\n",
    "    return Images\n",
    "\n",
    "# inner function used by load_image\n",
    "def randome_rotation_flip(image, imsize=224):\n",
    "    if random.randint(0, 1):\n",
    "        image = cv2.flip(image, 1)\n",
    "\n",
    "    if random.randint(0, 1):\n",
    "        angle = random.randint(-30, 30)\n",
    "        M = cv2.getRotationMatrix2D((imsize / 2, imsize / 2), angle, 1)\n",
    "        # third parameter: the transformed image size\n",
    "        image = cv2.warpAffine(image, M, (imsize, imsize))\n",
    "    return image\n",
    "\n",
    "# ----------------------------------------load data module end-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------network hyperparameter begin--------------------------------\n",
    "im_size = 224  # input image size\n",
    "batch_size = 20 \n",
    "epochs = 120\n",
    "x_shape  = (batch_size, 1, 224, 224)\n",
    "model_save = True\n",
    "model_reload = False\n",
    "drop_out_rate = 0.2\n",
    "my_init = keras.initializers.RandomNormal(mean=0.0, stddev=1.0, seed=None)\n",
    "\n",
    "# -----------------------------------network hyperparameter end--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenseNet(x):\n",
    "    x1 = Conv2D(16, (3,  3), activation='selu', padding='same', strides=(1, 1), data_format='channels_first')(x)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = concatenate([x1, x] , axis=1)                    \n",
    "                 \n",
    "    x2 = Conv2D(16, (3,  3), activation='relu', padding='same', strides=(1, 1), data_format='channels_first')(x1)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = concatenate([x2, x1, x] , axis=1) \n",
    "\n",
    "    x3 = Conv2D(32, (3,  3), activation='relu', padding='same', strides=(1, 1), data_format='channels_first')(x2)\n",
    "    x3 = Activation('relu')(x3)\n",
    "    x3 = concatenate([x3, x2, x1, x] , axis=1)\n",
    "\n",
    "    x4 = Conv2D(32, (3,  3), activation='relu', padding='same', strides=(1, 1), data_format='channels_first')(x3)\n",
    "    x4 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(x4)\n",
    "    return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1, 224, 224) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 224, 224) 160         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 224, 224) 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 17, 224, 224) 0           activation_9[0][0]               \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 224, 224) 2464        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 224, 224) 0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 34, 224, 224) 0           activation_10[0][0]              \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 224, 224) 9824        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 224, 224) 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 84, 224, 224) 0           activation_11[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 224, 224) 24224       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 32, 112, 112) 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_3 (Batch (None, 32, 112, 112) 128         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 112, 112) 0           batch_normalization_v2_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 112, 112) 4624        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 112, 112) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 48, 112, 112) 0           activation_12[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 112, 112) 6928        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 112, 112) 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 96, 112, 112) 0           activation_13[0][0]              \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 112, 112) 27680       concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 112, 112) 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 208, 112, 112 0           activation_14[0][0]              \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 112, 112) 59936       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 56, 56)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_4 (Batch (None, 32, 56, 56)   128         max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 56, 56)   0           batch_normalization_v2_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 56, 56)   4624        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 56, 56)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 48, 56, 56)   0           activation_15[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 56, 56)   6928        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 56, 56)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 96, 56, 56)   0           activation_16[0][0]              \n",
      "                                                                 concatenate_15[0][0]             \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 56, 56)   27680       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 56, 56)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 208, 56, 56)  0           activation_17[0][0]              \n",
      "                                                                 concatenate_16[0][0]             \n",
      "                                                                 concatenate_15[0][0]             \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 56, 56)   59936       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 32, 28, 28)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v2_5 (Batch (None, 32, 28, 28)   128         max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 28, 28)   0           batch_normalization_v2_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 28, 28)   2112        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 64, 1, 1)     0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 56)           3640        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 56)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            57          dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 241,201\n",
      "Trainable params: 241,009\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "inputs=Input(shape=(1, im_size, im_size))\n",
    "#224\n",
    "x = DenseNet(inputs)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Dropout(drop_out_rate)(x)\n",
    "#112\n",
    "x = DenseNet(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Dropout(drop_out_rate)(x)\n",
    "#56\n",
    "x = DenseNet(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Dropout(drop_out_rate)(x)\n",
    "#28\n",
    "x = Conv2D(64, (1,  1), activation='relu', padding='same', strides=(1, 1), data_format='channels_first')(x)\n",
    "x = MaxPooling2D(pool_size=(28, 28), data_format='channels_first')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dropout(drop_out_rate)(x)\n",
    "x = Dense(56, activation='relu')(x)\n",
    "\n",
    "x = Dropout(drop_out_rate)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "if model_reload:\n",
    "    model = keras.models.load_model('Dense_net_7_24.h5')\n",
    "else:\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image  500\n",
      "loading image  1000\n",
      "loading image  1500\n",
      "loading image  2000\n",
      "loading image  2500\n",
      "loading image  3000\n",
      "loading image  3500\n",
      "loading image  4000\n",
      "loading image  4500\n",
      "Starting normalization.......\n",
      "normalization finished\n",
      "(4931, 1, 224, 224)\n",
      "(4931,)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------load train data module begin-----------------------------\n",
    "\n",
    "# 训练数据\n",
    "im_size = 224\n",
    "x_train_path, y_train = load_path(data_set='train')\n",
    "x_train = load_image(x_train_path, imsize=im_size)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "  \n",
    "# -------------------------------load train data module end-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4437 samples, validate on 494 samples\n",
      "Epoch 1/120\n",
      "4437/4437 [==============================] - 119s 27ms/sample - loss: 0.8263 - accuracy: 0.5292 - val_loss: 0.7612 - val_accuracy: 0.1498\n",
      "Epoch 2/120\n",
      "4437/4437 [==============================] - 111s 25ms/sample - loss: 0.6988 - accuracy: 0.5391 - val_loss: 0.6370 - val_accuracy: 0.7935\n",
      "Epoch 3/120\n",
      "4437/4437 [==============================] - 111s 25ms/sample - loss: 0.6850 - accuracy: 0.5506 - val_loss: 0.6847 - val_accuracy: 0.7004\n",
      "Epoch 4/120\n",
      "4437/4437 [==============================] - 111s 25ms/sample - loss: 0.6774 - accuracy: 0.5711 - val_loss: 0.6230 - val_accuracy: 0.8198\n",
      "Epoch 5/120\n",
      "4437/4437 [==============================] - 111s 25ms/sample - loss: 0.6754 - accuracy: 0.5756 - val_loss: 0.6119 - val_accuracy: 0.8623\n",
      "Epoch 6/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6714 - accuracy: 0.5876 - val_loss: 0.6615 - val_accuracy: 0.3826\n",
      "Epoch 7/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6737 - accuracy: 0.5806 - val_loss: 0.5553 - val_accuracy: 0.8644\n",
      "Epoch 8/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6732 - accuracy: 0.5772 - val_loss: 0.6377 - val_accuracy: 0.8077\n",
      "Epoch 9/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6711 - accuracy: 0.5853 - val_loss: 0.5959 - val_accuracy: 0.9211\n",
      "Epoch 10/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6691 - accuracy: 0.5905 - val_loss: 0.6069 - val_accuracy: 0.8563\n",
      "Epoch 11/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6690 - accuracy: 0.5815 - val_loss: 0.5610 - val_accuracy: 0.9453\n",
      "Epoch 12/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6685 - accuracy: 0.5882 - val_loss: 0.6582 - val_accuracy: 0.6842\n",
      "Epoch 13/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6601 - accuracy: 0.6087 - val_loss: 0.8283 - val_accuracy: 0.1498\n",
      "Epoch 14/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6607 - accuracy: 0.6067 - val_loss: 0.5572 - val_accuracy: 0.8603\n",
      "Epoch 15/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6563 - accuracy: 0.6160 - val_loss: 0.5150 - val_accuracy: 0.9190\n",
      "Epoch 16/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6501 - accuracy: 0.6173 - val_loss: 0.5893 - val_accuracy: 0.9413\n",
      "Epoch 17/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6462 - accuracy: 0.6308 - val_loss: 0.6160 - val_accuracy: 0.7915\n",
      "Epoch 18/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6388 - accuracy: 0.6360 - val_loss: 0.6147 - val_accuracy: 0.6012\n",
      "Epoch 19/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6430 - accuracy: 0.6374 - val_loss: 0.6551 - val_accuracy: 0.6437\n",
      "Epoch 20/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6273 - accuracy: 0.6477 - val_loss: 0.6485 - val_accuracy: 0.7227\n",
      "Epoch 21/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6174 - accuracy: 0.6597 - val_loss: 0.8968 - val_accuracy: 0.3623\n",
      "Epoch 22/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6166 - accuracy: 0.6615 - val_loss: 0.5164 - val_accuracy: 0.9089\n",
      "Epoch 23/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.6090 - accuracy: 0.6703 - val_loss: 0.7060 - val_accuracy: 0.7045\n",
      "Epoch 24/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5996 - accuracy: 0.6750 - val_loss: 0.5861 - val_accuracy: 0.8178\n",
      "Epoch 25/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5865 - accuracy: 0.6928 - val_loss: 0.6153 - val_accuracy: 0.8320\n",
      "Epoch 26/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5767 - accuracy: 0.7023 - val_loss: 1.5146 - val_accuracy: 0.3988\n",
      "Epoch 27/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5860 - accuracy: 0.7007 - val_loss: 0.5323 - val_accuracy: 0.9069\n",
      "Epoch 28/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5821 - accuracy: 0.7036 - val_loss: 0.5288 - val_accuracy: 0.7996\n",
      "Epoch 29/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5743 - accuracy: 0.7014 - val_loss: 0.4825 - val_accuracy: 0.9352\n",
      "Epoch 30/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5653 - accuracy: 0.7165 - val_loss: 0.4809 - val_accuracy: 0.9271\n",
      "Epoch 31/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5688 - accuracy: 0.7149 - val_loss: 0.6429 - val_accuracy: 0.7794\n",
      "Epoch 32/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5605 - accuracy: 0.7235 - val_loss: 0.4922 - val_accuracy: 0.9494\n",
      "Epoch 33/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5536 - accuracy: 0.7271 - val_loss: 0.6053 - val_accuracy: 0.8036\n",
      "Epoch 34/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5447 - accuracy: 0.7372 - val_loss: 0.4955 - val_accuracy: 0.9211\n",
      "Epoch 35/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5426 - accuracy: 0.7338 - val_loss: 0.5596 - val_accuracy: 0.8482\n",
      "Epoch 36/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5455 - accuracy: 0.7368 - val_loss: 0.4418 - val_accuracy: 0.9393\n",
      "Epoch 37/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5353 - accuracy: 0.7428 - val_loss: 0.5898 - val_accuracy: 0.8259\n",
      "Epoch 38/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5325 - accuracy: 0.7437 - val_loss: 0.5113 - val_accuracy: 0.8765\n",
      "Epoch 39/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5261 - accuracy: 0.7417 - val_loss: 0.4709 - val_accuracy: 0.9332\n",
      "Epoch 40/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5242 - accuracy: 0.7415 - val_loss: 0.4772 - val_accuracy: 0.9190\n",
      "Epoch 41/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5131 - accuracy: 0.7543 - val_loss: 0.4408 - val_accuracy: 0.9211\n",
      "Epoch 42/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5164 - accuracy: 0.7523 - val_loss: 0.5202 - val_accuracy: 0.8866\n",
      "Epoch 43/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5071 - accuracy: 0.7656 - val_loss: 0.5364 - val_accuracy: 0.8846\n",
      "Epoch 44/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5006 - accuracy: 0.7661 - val_loss: 0.4432 - val_accuracy: 0.9231\n",
      "Epoch 45/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4997 - accuracy: 0.7706 - val_loss: 0.4971 - val_accuracy: 0.8765\n",
      "Epoch 46/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5015 - accuracy: 0.7701 - val_loss: 0.5668 - val_accuracy: 0.8563\n",
      "Epoch 47/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.5039 - accuracy: 0.7625 - val_loss: 0.5163 - val_accuracy: 0.9028\n",
      "Epoch 48/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4834 - accuracy: 0.7776 - val_loss: 0.3668 - val_accuracy: 0.9595\n",
      "Epoch 49/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4841 - accuracy: 0.7787 - val_loss: 0.4899 - val_accuracy: 0.9130\n",
      "Epoch 50/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4896 - accuracy: 0.7712 - val_loss: 0.4403 - val_accuracy: 0.9717\n",
      "Epoch 51/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4852 - accuracy: 0.7778 - val_loss: 0.3520 - val_accuracy: 0.9595\n",
      "Epoch 52/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4919 - accuracy: 0.7717 - val_loss: 0.5027 - val_accuracy: 0.8785\n",
      "Epoch 53/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4772 - accuracy: 0.7848 - val_loss: 0.5290 - val_accuracy: 0.8259\n",
      "Epoch 54/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4713 - accuracy: 0.7852 - val_loss: 0.8449 - val_accuracy: 0.5972\n",
      "Epoch 55/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4734 - accuracy: 0.7832 - val_loss: 0.5821 - val_accuracy: 0.8239\n",
      "Epoch 56/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4649 - accuracy: 0.7872 - val_loss: 0.2888 - val_accuracy: 0.9696\n",
      "Epoch 57/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4622 - accuracy: 0.7877 - val_loss: 0.4088 - val_accuracy: 0.9008\n",
      "Epoch 58/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4628 - accuracy: 0.7868 - val_loss: 0.4345 - val_accuracy: 0.9332\n",
      "Epoch 59/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4501 - accuracy: 0.7963 - val_loss: 0.5098 - val_accuracy: 0.8988\n",
      "Epoch 60/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4513 - accuracy: 0.7965 - val_loss: 0.5513 - val_accuracy: 0.8623\n",
      "Epoch 61/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4499 - accuracy: 0.7983 - val_loss: 0.4291 - val_accuracy: 0.9291\n",
      "Epoch 62/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4481 - accuracy: 0.7940 - val_loss: 0.3952 - val_accuracy: 0.9433\n",
      "Epoch 63/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4448 - accuracy: 0.8008 - val_loss: 0.5724 - val_accuracy: 0.8138\n",
      "Epoch 64/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4340 - accuracy: 0.7999 - val_loss: 0.3747 - val_accuracy: 0.9555\n",
      "Epoch 65/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4382 - accuracy: 0.8039 - val_loss: 0.4833 - val_accuracy: 0.9170\n",
      "Epoch 66/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4287 - accuracy: 0.8041 - val_loss: 0.4727 - val_accuracy: 0.8785\n",
      "Epoch 67/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4239 - accuracy: 0.8154 - val_loss: 0.4483 - val_accuracy: 0.8866\n",
      "Epoch 68/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4243 - accuracy: 0.8118 - val_loss: 0.6162 - val_accuracy: 0.7996\n",
      "Epoch 69/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4212 - accuracy: 0.8080 - val_loss: 0.7765 - val_accuracy: 0.6822\n",
      "Epoch 70/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4130 - accuracy: 0.8134 - val_loss: 0.5175 - val_accuracy: 0.8421\n",
      "Epoch 71/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4239 - accuracy: 0.8138 - val_loss: 0.3981 - val_accuracy: 0.9312\n",
      "Epoch 72/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4119 - accuracy: 0.8105 - val_loss: 0.6157 - val_accuracy: 0.7915\n",
      "Epoch 73/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4105 - accuracy: 0.8195 - val_loss: 0.4968 - val_accuracy: 0.8704\n",
      "Epoch 74/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.4183 - accuracy: 0.8123 - val_loss: 0.3908 - val_accuracy: 0.9271\n",
      "Epoch 75/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3997 - accuracy: 0.8195 - val_loss: 0.5171 - val_accuracy: 0.8947\n",
      "Epoch 76/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3923 - accuracy: 0.8174 - val_loss: 0.5632 - val_accuracy: 0.8401\n",
      "Epoch 77/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3936 - accuracy: 0.8233 - val_loss: 0.5079 - val_accuracy: 0.8765\n",
      "Epoch 78/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3934 - accuracy: 0.8274 - val_loss: 0.5021 - val_accuracy: 0.9069\n",
      "Epoch 79/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3944 - accuracy: 0.8208 - val_loss: 0.5839 - val_accuracy: 0.7874\n",
      "Epoch 80/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3891 - accuracy: 0.8267 - val_loss: 0.5909 - val_accuracy: 0.8543\n",
      "Epoch 81/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3709 - accuracy: 0.8343 - val_loss: 0.4403 - val_accuracy: 0.9150\n",
      "Epoch 82/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3874 - accuracy: 0.8287 - val_loss: 0.6169 - val_accuracy: 0.8219\n",
      "Epoch 83/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3769 - accuracy: 0.8343 - val_loss: 0.4671 - val_accuracy: 0.8826\n",
      "Epoch 84/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3737 - accuracy: 0.8391 - val_loss: 0.6212 - val_accuracy: 0.8138\n",
      "Epoch 85/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3782 - accuracy: 0.8296 - val_loss: 0.5727 - val_accuracy: 0.8644\n",
      "Epoch 86/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3708 - accuracy: 0.8350 - val_loss: 0.7520 - val_accuracy: 0.7429\n",
      "Epoch 87/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3766 - accuracy: 0.8323 - val_loss: 0.5273 - val_accuracy: 0.8421\n",
      "Epoch 88/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3417 - accuracy: 0.8513 - val_loss: 0.3924 - val_accuracy: 0.9211\n",
      "Epoch 89/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3569 - accuracy: 0.8420 - val_loss: 0.5066 - val_accuracy: 0.8664\n",
      "Epoch 90/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3469 - accuracy: 0.8440 - val_loss: 0.5654 - val_accuracy: 0.8462\n",
      "Epoch 91/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3418 - accuracy: 0.8485 - val_loss: 0.5228 - val_accuracy: 0.8785\n",
      "Epoch 92/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3465 - accuracy: 0.8485 - val_loss: 0.3960 - val_accuracy: 0.8988\n",
      "Epoch 93/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3433 - accuracy: 0.8456 - val_loss: 0.5289 - val_accuracy: 0.8300\n",
      "Epoch 94/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3398 - accuracy: 0.8474 - val_loss: 0.5963 - val_accuracy: 0.8057\n",
      "Epoch 95/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3361 - accuracy: 0.8517 - val_loss: 0.7148 - val_accuracy: 0.7753\n",
      "Epoch 96/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3326 - accuracy: 0.8549 - val_loss: 0.4389 - val_accuracy: 0.8806\n",
      "Epoch 97/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3287 - accuracy: 0.8609 - val_loss: 0.6469 - val_accuracy: 0.7449\n",
      "Epoch 98/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3332 - accuracy: 0.8537 - val_loss: 0.4200 - val_accuracy: 0.8826\n",
      "Epoch 99/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3167 - accuracy: 0.8623 - val_loss: 0.6484 - val_accuracy: 0.7591\n",
      "Epoch 100/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3046 - accuracy: 0.8715 - val_loss: 0.5139 - val_accuracy: 0.8826\n",
      "Epoch 101/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3334 - accuracy: 0.8564 - val_loss: 0.4955 - val_accuracy: 0.8381\n",
      "Epoch 102/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3165 - accuracy: 0.8661 - val_loss: 0.3589 - val_accuracy: 0.9008\n",
      "Epoch 103/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3116 - accuracy: 0.8627 - val_loss: 0.4667 - val_accuracy: 0.8725\n",
      "Epoch 104/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3012 - accuracy: 0.8659 - val_loss: 0.5673 - val_accuracy: 0.8057\n",
      "Epoch 105/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3042 - accuracy: 0.8677 - val_loss: 0.5036 - val_accuracy: 0.8583\n",
      "Epoch 106/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.2887 - accuracy: 0.8790 - val_loss: 0.6234 - val_accuracy: 0.8016\n",
      "Epoch 107/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3003 - accuracy: 0.8673 - val_loss: 0.7346 - val_accuracy: 0.7571\n",
      "Epoch 108/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.2856 - accuracy: 0.8711 - val_loss: 0.7001 - val_accuracy: 0.8077\n",
      "Epoch 109/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.2903 - accuracy: 0.8702 - val_loss: 0.7539 - val_accuracy: 0.7794\n",
      "Epoch 110/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.2963 - accuracy: 0.8749 - val_loss: 0.5895 - val_accuracy: 0.8603\n",
      "Epoch 111/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.2743 - accuracy: 0.8772 - val_loss: 0.6820 - val_accuracy: 0.8036\n",
      "Epoch 112/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.2837 - accuracy: 0.8812 - val_loss: 0.8023 - val_accuracy: 0.7814\n",
      "Epoch 113/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.3004 - accuracy: 0.8713 - val_loss: 0.7314 - val_accuracy: 0.7874\n",
      "Epoch 114/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.2768 - accuracy: 0.8837 - val_loss: 0.4375 - val_accuracy: 0.8907\n",
      "Epoch 115/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.2767 - accuracy: 0.8828 - val_loss: 0.7250 - val_accuracy: 0.8178\n",
      "Epoch 116/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.2819 - accuracy: 0.8824 - val_loss: 0.4117 - val_accuracy: 0.9049\n",
      "Epoch 117/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.2724 - accuracy: 0.8844 - val_loss: 0.7273 - val_accuracy: 0.7814\n",
      "Epoch 118/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.2700 - accuracy: 0.8835 - val_loss: 0.4537 - val_accuracy: 0.8806\n",
      "Epoch 119/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.2666 - accuracy: 0.8830 - val_loss: 0.6859 - val_accuracy: 0.8036\n",
      "Epoch 120/120\n",
      "4437/4437 [==============================] - 110s 25ms/sample - loss: 0.2863 - accuracy: 0.8729 - val_loss: 0.7599 - val_accuracy: 0.7996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ee0acc0f28>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 开始训练\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting normalization.......\n",
      "normalization finished\n",
      "465/465 [==============================] - 3s 6ms/sample - loss: 0.7240 - accuracy: 0.7505\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "x_test_path, y_test = load_path(data_set='valid')\n",
    "x_test = load_image(x_test_path, im_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465/465 [==============================] - 3s 7ms/sample - loss: 0.7240 - accuracy: 0.7505\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(x_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_save:\n",
    "    model.save('Dense_net_7_24.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
